
networks:
  hadoopnet:
    driver: overlay

services:

  headnode:
    image: remstef/hadoop3-jobimtext
    hostname: headnode
    command: >-
      /bin/bash -c "
        ssh-server & 
        hdfs namenode & 
        sleep 2 && yarn resourcemanager &
        sleep 3 && mapred historyserver & 
        wait
      "
    volumes:
      # pass authorized_keys for quicker login
      - ~/.ssh/authorized_keys:/opt/hadoop/.ssh/authorized_keys:ro
    networks:
      hadoopnet:
        aliases: 
          - namenode
          - resourcemanager
          - historyserver
    ports:
      - 2222:22
    env_file:
      - ./config-h3-nodes-swarm.env
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-hadoop/dfs/name"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
        constraints:
          - node.labels.hadooprole == master

  node01: &workernoderef
    image: remstef/hadoop3
    hostname: node01
    command: >-
      /bin/bash -c "
        hdfs datanode &
        sleep 1 && yarn nodemanager & 
        wait
      "
    env_file:
      - ./config-h3-nodes-swarm.env
    environment:
      - SLEEP_SECONDS=5
      - WAITFOR=headnode:8020
    networks:
      - hadoopnet
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
        constraints:
          - node.labels.hadooprole == worker2

  node02:
    <<: *workernoderef
    hostname: node02
    deploy:
      placement:
        constraints:
          - node.labels.hadooprole == worker2

  node03:
    <<: *workernoderef
    hostname: node03
    deploy:
      placement:
        constraints:
          - node.labels.hadooprole == worker3
