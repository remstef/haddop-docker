
networks:
  hadoopnet:
    driver: overlay

services:

  sshgateway:
    image: linuxserver/openssh-server
    hostname: sshgateway
    restart: unless-stopped
    ports:
      - target: 2222
        published: 2222
        protocol: tcp
        mode: host
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=UTC
      - USER_NAME=sshuser
      - USER_PASSWORD=hadoop
      - PASSWORD_ACCESS=true
    volumes:
      - ./gatewayserver__sshd_config:/etc/ssh/sshd_config:ro
    networks:
      - hadoopnet
    deploy:
      endpoint_mode: dnsrr
      mode: global
      placement:
        constraints:
          - node.labels.hadooprole == master

  namenode:
    image: remstef/hadoop3-jobimtext
    env_file:
      - ./config-h3-swarm.env
    hostname: namenode
    command: [ "hdfs", "namenode" ]
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-hadoop/dfs/name"
    networks:
      - hadoopnet
    deploy:
      endpoint_mode: dnsrr
      mode: global
      placement:
        constraints:
          - node.labels.hadooprole == master

  datanode1: &hadoopref
    image: remstef/hadoop3
    env_file:
      - ./config-h3-swarm.env
    hostname: datanode1
    command: [ "hdfs", "datanode" ]
    networks:
      - hadoopnet
    deploy:
      endpoint_mode: dnsrr
      mode: global
      placement:
        constraints:
          - node.labels.hadooprole == worker1

  datanode2:
    <<: *hadoopref
    hostname: datanode2
    deploy:
      endpoint_mode: dnsrr
      mode: global
      placement:
        constraints:
          - node.labels.hadooprole == worker2

  datanode3:
    <<: *hadoopref
    hostname: datanode3
    deploy:
      endpoint_mode: dnsrr
      mode: global
      placement:
        constraints:
          - node.labels.hadooprole == worker3
  
  resourcemanager:
    <<: *hadoopref
    hostname: resourcemanager
    command: [ "yarn", "resourcemanager" ]
    deploy:
      endpoint_mode: dnsrr
      mode: global
      placement:
        constraints:
          - node.labels.hadooprole == master

  nodemanager1:
    <<: *hadoopref
    hostname: nodemanager1
    command: [ "yarn", "nodemanager" ]
    deploy:
      endpoint_mode: dnsrr
      mode: global
      placement:
        constraints:
          - node.labels.hadooprole == worker1

  nodemanager2:
    <<: *hadoopref
    hostname: nodemanager2
    command: [ "yarn", "nodemanager" ]
    deploy:
      endpoint_mode: dnsrr
      mode: global
      placement:
        constraints:
          - node.labels.hadooprole == worker2

  nodemanager3:
    <<: *hadoopref
    hostname: nodemanager3
    command: [ "yarn", "nodemanager" ]
    deploy:
      endpoint_mode: dnsrr
      mode: global
      placement:
        constraints:
          - node.labels.hadooprole == worker3

  historyserver:
    <<: *hadoopref
    hostname: historyserver
    command: [ "mapred", "historyserver" ]
    deploy:
      endpoint_mode: dnsrr
      mode: global
      placement:
        constraints:
          - node.labels.hadooprole == worker1
